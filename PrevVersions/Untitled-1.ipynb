{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINIMISE \n",
    "$\\\\f_1(x) = 10x_1 + 2x_2\\\\$\n",
    "$f_2(x) = 3x_1 ^ 2 + 2x_2 ^ 2$ \n",
    "\n",
    "SUBJECT TO\n",
    "$\\\\ x_1 \\geq 2\\\\$\n",
    "$ x_2 \\geq 3 \\\\$\n",
    "$ x_1 + x_2 \\leq 12$\n",
    "\n",
    "Both f_1 and f_2 are continously differentiable \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim of problem\n",
    "min f(x) sub to contraints\n",
    "Quasi-Newton methods\n",
    "B_n approx = nabla ^2 f(x_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def search_dir(x, grads, B,n_args, printRes = False):\n",
    "\n",
    "    def obj(d,B,grads, x):\n",
    "        return np.max([(grad(x)).T @ d + 0.5 * d.T @ B_j @ d for grad, B_j in zip(grads, B)])\n",
    "    \n",
    "    \n",
    "    result = minimize(obj, d0, args=(B, grads))\n",
    "    \n",
    "     # Initial guess for d\n",
    "    d0 = np.zeros(n_args)\n",
    "\n",
    "    # Minimize the objective function\n",
    "    result = minimize(obj, d0, args=(B, grads,x))\n",
    "\n",
    "    dOpt = result.x\n",
    "    thetaOpt = result.fun\n",
    "\n",
    "    return dOpt, thetaOpt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Delta(grads,x,d):\n",
    "    return np.max([grad(x).T @ d for grad in grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Armijo(F,grads, x, alpha, d, c1):\n",
    "    for f in F:\n",
    "        if f(x + alpha * d) > f(x) + c1 * alpha * Delta(grads, x, d):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Curvature(F, grads, x, alpha, d, c2):\n",
    "    if Delta(grads,x + alpha * d,d) >= c2 * Delta(grads, x,d):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WLinesearch(F,grads, x,d,c1 = 0.1, c2 = 0.9):\n",
    "    alpha = 1\n",
    "    alpha_bar = 0\n",
    "    alpha_hat = 0\n",
    "    armijo_test = Armijo(F, grads, x, alpha, d, c1)\n",
    "    curvature_test = Curvature(F, grads, x, alpha, d, c2)\n",
    "\n",
    "    while not armijo_test or not curvature_test:\n",
    "        if not armijo_test:\n",
    "            alpha_bar = alpha\n",
    "            alpha = (alpha_bar + alpha_hat) / 2\n",
    "        elif not curvature_test:\n",
    "            alpha_bar = alpha\n",
    "\n",
    "            if alpha_hat == 0:\n",
    "                alpha = 2 * alpha_bar\n",
    "            else:\n",
    "                alpha = (alpha_bar + alpha_hat) / 2\n",
    "        \n",
    "        armijo_test = Armijo(F, grads, x, alpha, d, c1)\n",
    "        curvature_test = Curvature(F, grads, x, alpha, d, c2)\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "\n",
    "\n",
    "def BFGS(F, grads,B0, x0, x1):\n",
    "    #Preperation\n",
    "    y = np.array([grad(x1) - grad(x0) for grad in grads])\n",
    "    s = x1 - x0\n",
    "    if s.T @ y > 0:\n",
    "        p = 1/(s.T @ y)\n",
    "    else:\n",
    "        p = 1/ ( Delta(grads,x1,s) - np.array([grad(x0) for grad in grads]).T @ s)\n",
    "\n",
    "\n",
    "    #Update B\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(F,grads, x, B, c1, c2, iter = 100, tol = 1e-6):\n",
    "\n",
    "    n_args = len(x)\n",
    "    x0 = x\n",
    "    B0 = B\n",
    "    for i in range(iter):\n",
    "\n",
    "        #Step 1: Search direction\n",
    "        d,theta = search_dir(x0, grads, B0, n_args)\n",
    "\n",
    "        #Stopping criterion\n",
    "        if abs(theta) < tol:\n",
    "            return x\n",
    "        \n",
    "        #Line search\n",
    "        alpha = WLinesearch(F, grads, x, d, c1, c2)\n",
    "        x_new = x + alpha * d\n",
    "\n",
    "        sk = x_new - x\n",
    "\n",
    "        #B_new = B + (grads(x_new) @ grads(x_new).T) / (grads(x_new).T @ d) - (B @ d @ d.T @ B) / (d.T @ B @ d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
